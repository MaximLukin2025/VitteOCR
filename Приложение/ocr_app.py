# -*- coding: utf-8 -*-
"""
OCR â†’ GPT-4o Vision ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¾Ñ€ + Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ñ‹Ğ¹ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Â«ÑĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚ Ğ’Ğ¸Ñ‚Ñ‚Ğµ / Ğ½Ğµ Ğ’Ğ¸Ñ‚Ñ‚ĞµÂ»
"""

###############################################################################
# 0 â”€â”€â”€ system imports (Ğ±ĞµĞ· Streamlit-ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´)
###############################################################################
import os, sys, io, re, json, base64, subprocess, difflib, pickle
from pathlib import Path
from typing import List, Dict

import numpy as np
import cv2, pytesseract, openai, Levenshtein as Lev
from PIL import Image
from tensorflow.keras.models import load_model     # â† Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°

###############################################################################
# 1 â”€â”€â”€ constants / init
###############################################################################
ROOT         = Path(__file__).parent
RULES_PATH   = ROOT / "rules.txt"
MODEL_PATH   = ROOT / "best_model.h5"
VECT_PATH    = ROOT / "tfidf_vectorizer.pkl"

TILE_SIDE, OVERLAP = 1024, 64

REFUSAL_RGX = re.compile(
    r"(i['â€™]?\s?m (sorry|unable)|i can('| )?t|i cannot|"
    r"Ğ¸Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ[, ]*Ñ Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ|Ğº ÑĞ¾Ğ¶Ğ°Ğ»ĞµĞ½Ğ¸Ñ[, ]*Ñ Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ|Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ)",
    re.I,
)

API_KEY    = "sk-2uHtBOkjr3ZrCn43aUt4WdEZ20JaXu49" # â† Ğ·Ğ°Ğ¼ĞµĞ½Ğ¸Ñ‚Ğµ
PROXY_BASE = "https://api.proxyapi.ru/openai/v1"
GPT_MODEL  = "gpt-4o"
GPT_TO     = 25
client     = openai.OpenAI(api_key=API_KEY, base_url=PROXY_BASE)

###############################################################################
# 2 â”€â”€â”€ streamlit bootstrap (ĞĞ• Ğ£Ğ”ĞĞ›Ğ¯Ğ¢Ğ¬)
###############################################################################
from streamlit.web import cli as stcli
from streamlit import runtime
import streamlit as st

###############################################################################
# 3 â”€â”€â”€ helpers (Ğ±ĞµĞ· Streamlit-Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²)
###############################################################################
def configure_tesseract() -> str:
    guess = [Path(r"C:\Program Files\Tesseract-OCR\tesseract.exe"),
             Path(r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe")]
    exe = next((p for p in guess if p.exists()), None)
    if not exe:
        return ""
    pytesseract.pytesseract.tesseract_cmd = str(exe)
    os.environ["TESSDATA_PREFIX"] = str(exe.parent / "tessdata")
    try:
        return subprocess.check_output([str(exe), "--version"],
                                       text=True).splitlines()[0]
    except subprocess.CalledProcessError:
        return ""

@st.cache_resource
def load_rules() -> List[str]:
    if RULES_PATH.exists():
        return [l.strip() for l in RULES_PATH.read_text("utf8").splitlines()
                if l.strip()]
    return []

def apply_rules(text: str, rules: List[str]) -> str:
    """
    ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°
      â€¢ s/Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾/Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾/
      â€¢ delete(ÑÑ‚Ñ€Ğ¾ĞºĞ°_Ğ´Ğ»Ñ_ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ)
    Ğº Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ Ñ‚ĞµĞºÑÑ‚Ñƒ OCR.
    """
    for r in rules:
        if r.startswith("s/") and r.count("/") >= 3:
            _, bad, good, _ = r.split("/", 3)
            text = text.replace(bad, good)
        elif r.startswith("delete(") and r.endswith(")"):
            text = text.replace(r[7:-1], "")
    return text

# â”€â”€ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Â«Ğ’Ğ¸Ñ‚Ñ‚Ğµ / Ğ½Ğµ Ğ’Ğ¸Ñ‚Ñ‚ĞµÂ» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_cls():
    if not (MODEL_PATH.exists() and VECT_PATH.exists()):
        return None, None
    model  = load_model(MODEL_PATH)
    with open(VECT_PATH, "rb") as f:
        vect = pickle.load(f)
    return model, vect

def classify(text: str, model, vect) -> (str, float):
    if model is None or vect is None:
        return "Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°", 0.0
    feats = vect.transform([text]).toarray()
    prob  = float(model.predict(feats).ravel()[0])   # >0.5 â‡’ Non-Vitte
    if prob > 0.5:
        return "Ğ½Ğµ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ÑÑ Ğº Ğ’Ğ¸Ñ‚Ñ‚Ğµ", prob
    else:
        return "Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ÑÑ Ğº Ğ’Ğ¸Ñ‚Ñ‚Ğµ", 1 - prob

# â”€â”€ OCR utils â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def tiles(pil: Image.Image):
    w, h = pil.size
    for y in range(0, h, TILE_SIDE - OVERLAP):
        for x in range(0, w, TILE_SIDE - OVERLAP):
            yield pil.crop((x, y, min(x+TILE_SIDE, w), min(y+TILE_SIDE, h)))

def table_preproc(pil: Image.Image, h_target=1400) -> Image.Image:
    g  = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2GRAY)
    thr = cv2.adaptiveThreshold(g,255,cv2.ADAPTIVE_THRESH_MEAN_C,
                                cv2.THRESH_BINARY_INV,17,11)
    hmask = cv2.morphologyEx(thr, cv2.MORPH_OPEN,
                             cv2.getStructuringElement(cv2.MORPH_RECT,(40,1)))
    vmask = cv2.morphologyEx(thr, cv2.MORPH_OPEN,
                             cv2.getStructuringElement(cv2.MORPH_RECT,(1,40)))
    clean = cv2.inpaint(g, cv2.bitwise_or(hmask, vmask), 3, cv2.INPAINT_NS)
    clahe = cv2.createCLAHE(2,(8,8)).apply(clean)
    binar = cv2.adaptiveThreshold(clahe,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                  cv2.THRESH_BINARY,31,9)
    w     = int(pil.width * h_target / pil.height)
    return Image.fromarray(cv2.resize(binar,(w,h_target),cv2.INTER_CUBIC))

def ocr_tess(pil: Image.Image) -> str:
    dens = np.mean(np.array(pil) < 200)
    for psm in ([3,6] if dens<.05 else [6,3]) + [4,11]:
        txt = pytesseract.image_to_string(pil, lang="rus",
                                          config=f"--oem 1 --psm {psm}").strip()
        if txt: return txt
    return ""

def to_b64(pil: Image.Image, max_side=768) -> str:
    w,h = pil.size
    if max(w,h) > max_side:
        s = max_side/max(w,h); pil = pil.resize((int(w*s), int(h*s)))
    buf = io.BytesIO(); pil.save(buf,"JPEG",quality=70,optimize=True)
    return base64.b64encode(buf.getvalue()).decode()

def safe_gpt(img_b64: str, context: str, tries=3) -> str:
    ctx_short = (context[:700]+"â€¦") if len(context)>700 else (context or "<Ğ½ĞµÑ‚ RAW>")
    prompts = [
        f"Ğ§ĞµÑ€Ğ½Ğ¾Ğ²Ğ¾Ğ¹ OCR:\nÂ«{ctx_short}Â».\nĞ˜ÑĞ¿Ñ€Ğ°Ğ²ÑŒ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸, Ñ‚ĞµĞºÑÑ‚ 100 % Ğ´Ğ¾ÑĞ»Ğ¾Ğ²Ğ½Ğ¾.",
        "Ğ’ĞµÑ€Ğ½Ğ¸ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹.",
        "Ğ¡Ğ´ĞµĞ»Ğ°Ğ¹ OCR-Ñ€Ğ°ÑÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²ĞºÑƒ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»-Ğ²-ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»."
    ]
    for i in range(tries):
        msg = [
            {"role":"system","content":
             "Ğ¢Ñ‹ OCR-Ğ´Ğ²Ğ¸Ğ¶Ğ¾Ğº. Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾. Ğ’ĞµÑ€Ğ½Ğ¸ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ¾ÑĞ»Ğ¾Ğ²Ğ½Ğ¾, Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ ÑĞºÑ€Ñ‹Ğ²Ğ°Ğ¹."},
            {"role":"user","content":[
                {"type":"text","text":prompts[i]},
                {"type":"image_url","image_url":{"url":f"data:image/jpeg;base64,{img_b64}"}}]},
        ]
        try:
            out = client.chat.completions.create(
                model=GPT_MODEL, timeout=GPT_TO,
                messages=msg, temperature=0, max_tokens=400
            ).choices[0].message.content.strip()
        except Exception: out = ""
        if out and not REFUSAL_RGX.search(out): return out
    return ""      # Ğ¾Ñ‚ĞºĞ°Ğ·

def diff_short(a: str, b: str, limit=12) -> str:
    lines = difflib.unified_diff(a.splitlines(), b.splitlines(),
                                 lineterm="", n=0)
    body = [l for l in lines if l.startswith(("+","-")) and l[1:].strip()]
    if len(body) > limit: body = body[:limit] + ["â€¦ (+ ĞµÑ‰Ñ‘ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ)"]
    fmt = lambda l: f'<span style="color:#e74c3c">{l}</span>' if l.startswith("-") \
                    else f'<span style="color:#1abc9c">{l}</span>'
    return "<br>".join(fmt(l) for l in body) or "â€” Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ Ğ½ĞµÑ‚ â€”"

def cer(a: str, b: str):
    a_clean = re.sub(r'\s+', '', a)
    b_clean = re.sub(r'\s+', '', b)
    total   = len(b_clean)
    if total == 0:
        return 0, 0, 0.0
    errors  = Lev.distance(a_clean, b_clean)
    return errors, total, errors/total

###############################################################################
# 4 â”€â”€â”€ Streamlit GUI
###############################################################################
def main() -> None:
    st.set_page_config("OCR + GPT ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¾Ñ€", "ğŸ“„", layout="wide")

    TESS  = configure_tesseract()
    RULES = load_rules()
    CLS_MODEL, VECT = load_cls()

    with st.sidebar:
        st.header("ğŸ“ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ ÑĞºÑ€Ğ¸Ğ½ÑˆĞ¾Ñ‚")
        up = st.file_uploader("Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ (jpg/png/tiff/pdf)",
                              type=["jpg","jpeg","png","tif","tiff","pdf"])
        st.header("âš™ï¸ ĞĞ¿Ñ†Ğ¸Ğ¸")
        tiles_on = st.checkbox("Ğ¢Ğ°Ğ¹Ğ»Ñ‹ 1024 px", True)
        gpt_on   = st.checkbox("Ğ˜ÑĞ¿. GPT-4o", True)
        rules_on = st.checkbox("ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ rules.txt", True)
        debug    = st.checkbox("ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ RAW Ğ¸ ĞŸĞ¾ÑĞ»Ğµ-Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»", False)

    st.title("ğŸ“„ OCR â†’ GPT ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¾Ñ€ + Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ’Ğ¸Ñ‚Ñ‚Ğµ")

    if not up:
        st.info("Ğ¡Ğ»ĞµĞ²Ğ° Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°.")
        return

    img = Image.open(up).convert("RGB")

    # â”€â”€ Ğ³Ñ€ÑƒĞ±Ñ‹Ğ¹ OCR Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    rough_txt = pytesseract.image_to_string(img, lang="rus")[:3000]
    label, conf = classify(rough_txt, CLS_MODEL, VECT)
    st.subheader("ğŸ·ï¸ ĞŸÑ€Ğ¸Ğ½Ğ°Ğ´Ğ»ĞµĞ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°")
    colA, colB = st.columns([1,4])
    with colA:
        st.image(img, use_container_width=True,
                 caption=f"{img.width}Ã—{img.height}px")
    with colB:
        clr = "#27ae60" if label.startswith("Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ÑÑ") else "#c0392b"
        st.markdown(f"<h3 style='color:{clr}'>{label}</h3>"
                    f"<p>Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: <b>{conf:.2%}</b></p>",
                    unsafe_allow_html=True)

    st.divider()

    # â”€â”€ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ†ĞµĞ½Ğ½Ñ‹Ğ¹ OCR-pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    parts = list(tiles(img)) if tiles_on else [img]
    raw_all, rule_all, fin_all = [], [], []

    for p in parts:
        proc = table_preproc(p)
        raw  = ocr_tess(proc)
        rule = apply_rules(raw, RULES) if rules_on else raw
        gpt  = safe_gpt(to_b64(proc), rule) if gpt_on else ""
        fin  = gpt or rule
        raw_all.append(raw); rule_all.append(rule); fin_all.append(fin)

    raw_txt  = "\n".join(raw_all)
    rule_txt = "\n".join(rule_all)
    fin_txt  = "\n".join(fin_all)

    st.subheader("ğŸ“ Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ (Ğ¿Ğ¾ÑĞ»Ğµ Ğ²ÑĞµÑ… Ğ¿Ñ€Ğ°Ğ²Ğ¾Ğº)")
    st.code(fin_txt or "â€”", language="markdown")

    st.markdown("#### ğŸ” Ğ§Ñ‚Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ğ»Ğ¾ÑÑŒ")
    st.markdown(diff_short(raw_txt, fin_txt), unsafe_allow_html=True)

    if debug:
        with st.expander("RAW / Tesseract"):
            st.code(raw_txt or "â€”", language="markdown")
        with st.expander("ĞŸĞ¾ÑĞ»Ğµ-Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»"):
            st.code(rule_txt or "â€”", language="markdown")

###############################################################################
# 5 â”€â”€â”€ run
###############################################################################
if __name__ == "__main__":
    if runtime.exists():      # streamlit run app.py
        main()
    else:                      # python app.py
        sys.argv = ["streamlit", "run", sys.argv[0]]
        sys.exit(stcli.main())
